{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>ETL: Transform</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data is extracted, it is transformed to ensure that it is in a format that can be easily used for analysis. This involves preparation and cleaning of data. The data engineer may also need to apply business rules and data validation checks to ensure that the data is consistent and accurate.\n",
    "\n",
    "If the load is small, Pandas can be a great tool to use for data transformation although they are typically done using parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark aggregations\n",
    "aggregated_df = df.groupBy(\"column_x\").mean(\"column_y\")\n",
    "\n",
    "# PySpark joins\n",
    "df_A.join(\n",
    "    df_B,\n",
    "    df_A.column_id == df_B.column_id\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations are a big area of study. What is important to remember, is to organize each process in functions. These functions can then be applied on a dataframe inside an ETL pipeline."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
